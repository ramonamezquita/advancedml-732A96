plot(shorter_data$temp, type = "l")
#calculate distribution of estimated function from a gaussian process u
model <- gausspr(temp ~ time + day, data = shorter_data)
#use the predict function to get the posterior means for each data point
posterior_means <- predict(model, shorter_data)
plot(posterior_means, type = "l")
#define our own square exponential kernel function
se_kernel <- function(l, sigma, x, y){
x <- as.matrix(x)
y <- as.matrix(y)
x_len = nrow(x)
y_len = nrow(y)
kernel_matrix <- matrix(nrow = x_len, ncol = y_len)
for(i in 1:x_len){
for(j in 1:y_len){
kernel_matrix[i,j] <- sum((x[i,] - y[j,])^2)
}
}
kernel_matrix <- sigma^2*exp(-kernel_matrix/(2*l^2))
return(kernel_matrix)
}
#evaluate covariance of x=1 and x' = 2 with our function
cov_1 <- se_kernel(l = 1, sigma = 1, x = 1, y = 2)
library("kernlab")
#import the data set
data <- read.csv("https://github.com/STIMALiU/AdvMLCourse/raw/master/GaussianProcess/Code/TempTullinge.csv", header=TRUE, sep=";")
#extend the data with variable time, which just tracks days since start of the data set
data$time <- 1:nrow(data)
#day, which tracks which day or the year
data$day <- (data$time %% 365)
#important to replace each 0 with 365
data$day[which(data$day == 0)] <- 365
#use only every 6th element to speed up computations of the gp
shorter_data <- data[seq(1,nrow(data), 5), ]
#print the "true function" for
plot(shorter_data$temp, type = "l")
#calculate distribution of estimated function from a gaussian process u
model <- gausspr(temp ~ time + day, data = shorter_data)
#use the predict function to get the posterior means for each data point
posterior_means <- predict(model, shorter_data)
plot(posterior_means, type = "l")
#define our own square exponential kernel function
se_kernel <- function(l, sigma, x, y){
x <- as.matrix(x)
y <- as.matrix(y)
x_len = nrow(x)
y_len = nrow(y)
kernel_matrix <- matrix(nrow = x_len, ncol = y_len)
for(i in 1:x_len){
for(j in 1:y_len){
kernel_matrix[i,j] <- sum((x[i,] - y[j,])^2)
}
}
kernel_matrix <- sigma^2*exp(-kernel_matrix/(2*l^2))
return(kernel_matrix)
}
#evaluate covariance of x=1 and x' = 2 with our function
cov_1 <- se_kernel(l = 1, sigma = 1, x = 1, y = 2)
#use the kernelMatrix function
#to compute the covariance matrix K(X, X∗) for the input vectors X = (1, 3, 4)T and
# X∗ = (2, 3, 4)T
#we set l = 1
x <- c(1, 3, 4)
y <- c(2, 3, 4)
l <- 1
k <- rbfdot(sigma = 1/(2*l^2))
cov_2 <- kernelMatrix(k, x, y)
cov_2
t <- se(l = 1, sigma = 1, x, y)
t <- se_kernel(l = 1, sigma = 1, x, y)
View(t)
library("kernlab")
#import the data set
data <- read.csv("https://github.com/STIMALiU/AdvMLCourse/raw/master/GaussianProcess/Code/TempTullinge.csv", header=TRUE, sep=";")
#extend the data with variable time, which just tracks days since start of the data set
data$time <- 1:nrow(data)
#day, which tracks which day or the year
data$day <- (data$time %% 365)
#important to replace each 0 with 365
data$day[which(data$day == 0)] <- 365
#use only every 6th element to speed up computations of the gp
shorter_data <- data[seq(1,nrow(data), 5), ]
#print the "true function" for
plot(shorter_data$temp, type = "l")
#calculate distribution of estimated function from a gaussian process u
model <- gausspr(temp ~ time + day, data = shorter_data)
#use the predict function to get the posterior means for each data point
posterior_means <- predict(model, shorter_data)
plot(posterior_means, type = "l")
#define our own square exponential kernel function
se_kernel <- function(l, sigma, x, y){
k <- function(x, y) {
sigma^2 * exp(-sum((x - y)^2) / (2 * l^2))
}
class(k) <- "kernel"
}
# se_kernel <- function(l, sigma, x, y){
#   x <- as.matrix(x)
#   y <- as.matrix(y)
#   x_len = nrow(x)
#   y_len = nrow(y)
#   kernel_matrix <- matrix(nrow = x_len, ncol = y_len)
#   for(i in 1:x_len){
#     for(j in 1:y_len){
#       kernel_matrix[i,j] <- sum((x[i,] - y[j,])^2)
#     }
#   }
#   kernel_matrix <- sigma^2*exp(-kernel_matrix/(2*l^2))
#   return(kernel_matrix)
# }
#evaluate covariance of x=1 and x' = 2 with our function
cov_1 <- se_kernel(l = 1, sigma = 1, x = 1, y = 2)
print(cov_1)
#use the kernelMatrix function
#to compute the covariance matrix K(X, X∗) for the input vectors X = (1, 3, 4)T and
# X∗ = (2, 3, 4)T
x <- c(1, 3, 4)
y <- c(2, 3, 4)
#we set l = 1
l <- 1
k <- se_kernel(l = 1, sigma = 1)
cov_2 <- kernelMatrix(k, x, y)
library("kernlab")
#import the data set
data <- read.csv("https://github.com/STIMALiU/AdvMLCourse/raw/master/GaussianProcess/Code/TempTullinge.csv", header=TRUE, sep=";")
#extend the data with variable time, which just tracks days since start of the data set
data$time <- 1:nrow(data)
#day, which tracks which day or the year
data$day <- (data$time %% 365)
#important to replace each 0 with 365
data$day[which(data$day == 0)] <- 365
#use only every 6th element to speed up computations of the gp
shorter_data <- data[seq(1,nrow(data), 5), ]
#print the "true function" for
plot(shorter_data$temp, type = "l")
#calculate distribution of estimated function from a gaussian process u
model <- gausspr(temp ~ time + day, data = shorter_data)
#use the predict function to get the posterior means for each data point
posterior_means <- predict(model, shorter_data)
plot(posterior_means, type = "l")
#define our own square exponential kernel function
se_kernel <- function(l, sigma, x, y){
k <- function(x, y) {
sigma^2 * exp(-sum((x - y)^2) / (2 * l^2))
}
class(k) <- "kernel"
return(k)
}
# se_kernel <- function(l, sigma, x, y){
#   x <- as.matrix(x)
#   y <- as.matrix(y)
#   x_len = nrow(x)
#   y_len = nrow(y)
#   kernel_matrix <- matrix(nrow = x_len, ncol = y_len)
#   for(i in 1:x_len){
#     for(j in 1:y_len){
#       kernel_matrix[i,j] <- sum((x[i,] - y[j,])^2)
#     }
#   }
#   kernel_matrix <- sigma^2*exp(-kernel_matrix/(2*l^2))
#   return(kernel_matrix)
# }
#evaluate covariance of x=1 and x' = 2 with our function
cov_1 <- se_kernel(l = 1, sigma = 1, x = 1, y = 2)
print(cov_1)
#use the kernelMatrix function
#to compute the covariance matrix K(X, X∗) for the input vectors X = (1, 3, 4)T and
# X∗ = (2, 3, 4)T
x <- c(1, 3, 4)
y <- c(2, 3, 4)
#we set l = 1
l <- 1
k <- se_kernel(l = 1, sigma = 1)
cov_2 <- kernelMatrix(k, x, y)
print(cov_2)
# factory to make a kernel function kernlab can use from our custom kernel function
#set the kernel with l = 100 and sigma = 20
kern <- se_kernel(l = 100, sigma = 20)
# GP with variance sigma_f^2
gp_model <- gausspr(temp ~ time, data = shorter_data, kernel = kern,
scaled = FALSE)  # ensures kernel is not rescaled
library("kernlab")
#import the data set
data <- read.csv("https://github.com/STIMALiU/AdvMLCourse/raw/master/GaussianProcess/Code/TempTullinge.csv", header=TRUE, sep=";")
#extend the data with variable time, which just tracks days since start of the data set
data$time <- 1:nrow(data)
#day, which tracks which day or the year
data$day <- (data$time %% 365)
#important to replace each 0 with 365
data$day[which(data$day == 0)] <- 365
#use only every 6th element to speed up computations of the gp
shorter_data <- data[seq(1,nrow(data), 5), ]
#print the "true function" for
plot(shorter_data$temp, type = "l")
#calculate distribution of estimated function from a gaussian process u
model <- gausspr(temp ~ time + day, data = shorter_data)
#use the predict function to get the posterior means for each data point
posterior_means <- predict(model, shorter_data)
plot(posterior_means, type = "l")
#define our own square exponential kernel function
se_kernel <- function(l, sigma, x, y){
k <- function(x, y) {
sigma^2 * exp(-sum((x - y)^2) / (2 * l^2))
}
class(k) <- "kernel"
return(k)
}
# se_kernel <- function(l, sigma, x, y){
#   x <- as.matrix(x)
#   y <- as.matrix(y)
#   x_len = nrow(x)
#   y_len = nrow(y)
#   kernel_matrix <- matrix(nrow = x_len, ncol = y_len)
#   for(i in 1:x_len){
#     for(j in 1:y_len){
#       kernel_matrix[i,j] <- sum((x[i,] - y[j,])^2)
#     }
#   }
#   kernel_matrix <- sigma^2*exp(-kernel_matrix/(2*l^2))
#   return(kernel_matrix)
# }
#evaluate covariance of x=1 and x' = 2 with our function
cov_1 <- se_kernel(l = 1, sigma = 1, x = 1, y = 2)
print(cov_1)
#use the kernelMatrix function
#to compute the covariance matrix K(X, X∗) for the input vectors X = (1, 3, 4)T and
# X∗ = (2, 3, 4)T
x <- c(1, 3, 4)
y <- c(2, 3, 4)
#we set l = 1
l <- 1
k <- se_kernel(l = 1, sigma = 1)
cov_2 <- kernelMatrix(k, x, y)
print(cov_2)
# factory to make a kernel function kernlab can use from our custom kernel function
#set the kernel with l = 100 and sigma = 20
kern <- se_kernel(l = 100, sigma = 20)
# GP with variance sigma_f^2
gp_model <- gausspr(temp ~ time, data = shorter_data, kernel = kern, scaled = FALSE)  # ensures kernel is not rescaled
library("kernlab")
#import the data set
data <- read.csv("https://github.com/STIMALiU/AdvMLCourse/raw/master/GaussianProcess/Code/TempTullinge.csv", header=TRUE, sep=";")
#extend the data with variable time, which just tracks days since start of the data set
data$time <- 1:nrow(data)
#day, which tracks which day or the year
data$day <- (data$time %% 365)
#important to replace each 0 with 365
data$day[which(data$day == 0)] <- 365
#use only every 6th element to speed up computations of the gp
shorter_data <- data[seq(1,nrow(data), 5), ]
#print the "true function" for
plot(shorter_data$temp, type = "l")
#calculate distribution of estimated function from a gaussian process u
model <- gausspr(temp ~ time + day, data = shorter_data)
#use the predict function to get the posterior means for each data point
posterior_means <- predict(model, shorter_data)
plot(posterior_means, type = "l")
#define our own square exponential kernel function
se_kernel <- function(l, sigma, x, y){
k <- function(x, y) {
sigma^2 * exp(-sum((x - y)^2) / (2 * l^2))
}
class(k) <- "kernel"
return(k)
}
# se_kernel <- function(l, sigma, x, y){
#   x <- as.matrix(x)
#   y <- as.matrix(y)
#   x_len = nrow(x)
#   y_len = nrow(y)
#   kernel_matrix <- matrix(nrow = x_len, ncol = y_len)
#   for(i in 1:x_len){
#     for(j in 1:y_len){
#       kernel_matrix[i,j] <- sum((x[i,] - y[j,])^2)
#     }
#   }
#   kernel_matrix <- sigma^2*exp(-kernel_matrix/(2*l^2))
#   return(kernel_matrix)
# }
#evaluate covariance of x=1 and x' = 2 with our function
cov_1 <- se_kernel(l = 1, sigma = 1, x = 1, y = 2)
print(cov_1)
#use the kernelMatrix function
#to compute the covariance matrix K(X, X∗) for the input vectors X = (1, 3, 4)T and
# X∗ = (2, 3, 4)T
x <- c(1, 3, 4)
y <- c(2, 3, 4)
#we set l = 1
l <- 1
k <- se_kernel(l = 1, sigma = 1)
cov_2 <- kernelMatrix(k, x, y)
print(cov_2)
# factory to make a kernel function kernlab can use from our custom kernel function
#set the kernel with l = 100 and sigma = 20
kern <- se_kernel(l = 100, sigma = 20)
# GP with variance sigma_f^2
gp_model <- gausspr(formula = temp ~ time, data = shorter_data,
kernel = kern,
scaled = FALSE)
library("kernlab")
#import the data set
data <- read.csv("https://github.com/STIMALiU/AdvMLCourse/raw/master/GaussianProcess/Code/TempTullinge.csv", header=TRUE, sep=";")
#extend the data with variable time, which just tracks days since start of the data set
data$time <- 1:nrow(data)
#day, which tracks which day or the year
data$day <- (data$time %% 365)
#important to replace each 0 with 365
data$day[which(data$day == 0)] <- 365
#use only every 6th element to speed up computations of the gp
shorter_data <- data[seq(1,nrow(data), 5), ]
#print the "true function" for
plot(shorter_data$temp, type = "l")
#calculate distribution of estimated function from a gaussian process u
model <- gausspr(temp ~ time + day, data = shorter_data)
#use the predict function to get the posterior means for each data point
posterior_means <- predict(model, shorter_data)
plot(posterior_means, type = "l")
#define our own square exponential kernel function
se_kernel <- function(l, sigma, x, y){
k <- function(x, y) {
sigma^2 * exp(-sum((x - y)^2) / (2 * l^2))
}
class(k) <- "kernel"
return(k)
}
# se_kernel <- function(l, sigma, x, y){
#   x <- as.matrix(x)
#   y <- as.matrix(y)
#   x_len = nrow(x)
#   y_len = nrow(y)
#   kernel_matrix <- matrix(nrow = x_len, ncol = y_len)
#   for(i in 1:x_len){
#     for(j in 1:y_len){
#       kernel_matrix[i,j] <- sum((x[i,] - y[j,])^2)
#     }
#   }
#   kernel_matrix <- sigma^2*exp(-kernel_matrix/(2*l^2))
#   return(kernel_matrix)
# }
#evaluate covariance of x=1 and x' = 2 with our function
cov_1 <- se_kernel(l = 1, sigma = 1, x = 1, y = 2)
print(cov_1)
#use the kernelMatrix function
#to compute the covariance matrix K(X, X∗) for the input vectors X = (1, 3, 4)T and
# X∗ = (2, 3, 4)T
x <- c(1, 3, 4)
y <- c(2, 3, 4)
#we set l = 1
l <- 1
k <- se_kernel(l = 1, sigma = 1)
cov_2 <- kernelMatrix(k, x, y)
print(cov_2)
# factory to make a kernel function kernlab can use from our custom kernel function
#set the kernel with l = 100 and sigma = 20
kern <- se_kernel(l = 100, sigma = 20)
y <- shorter_data$temp
x <- shorter_data$time
# GP with variance sigma_f^2
gp_model <- gausspr(x =x, y =y,
kernel = kern,
scaled = FALSE)
View(gp_model)
library("kernlab")
#import the data set
data <- read.csv("https://github.com/STIMALiU/AdvMLCourse/raw/master/GaussianProcess/Code/TempTullinge.csv", header=TRUE, sep=";")
#extend the data with variable time, which just tracks days since start of the data set
data$time <- 1:nrow(data)
#day, which tracks which day or the year
data$day <- (data$time %% 365)
#important to replace each 0 with 365
data$day[which(data$day == 0)] <- 365
#use only every 6th element to speed up computations of the gp
shorter_data <- data[seq(1,nrow(data), 5), ]
#print the "true function" for
plot(shorter_data$temp, type = "l")
#calculate distribution of estimated function from a gaussian process u
model <- gausspr(temp ~ time + day, data = shorter_data)
#use the predict function to get the posterior means for each data point
posterior_means <- predict(model, shorter_data)
plot(posterior_means, type = "l")
#define our own square exponential kernel function
se_kernel <- function(l, sigma, x, y){
k <- function(x, y) {
sigma^2 * exp(-sum((x - y)^2) / (2 * l^2))
}
class(k) <- "kernel"
return(k)
}
# se_kernel <- function(l, sigma, x, y){
#   x <- as.matrix(x)
#   y <- as.matrix(y)
#   x_len = nrow(x)
#   y_len = nrow(y)
#   kernel_matrix <- matrix(nrow = x_len, ncol = y_len)
#   for(i in 1:x_len){
#     for(j in 1:y_len){
#       kernel_matrix[i,j] <- sum((x[i,] - y[j,])^2)
#     }
#   }
#   kernel_matrix <- sigma^2*exp(-kernel_matrix/(2*l^2))
#   return(kernel_matrix)
# }
#evaluate covariance of x=1 and x' = 2 with our function
cov_1 <- se_kernel(l = 1, sigma = 1, x = 1, y = 2)
print(cov_1)
#use the kernelMatrix function
#to compute the covariance matrix K(X, X∗) for the input vectors X = (1, 3, 4)T and
# X∗ = (2, 3, 4)T
x <- c(1, 3, 4)
y <- c(2, 3, 4)
#we set l = 1
l <- 1
k <- se_kernel(l = 1, sigma = 1)
cov_2 <- kernelMatrix(k, x, y)
print(cov_2)
#set the kernel with l = 100 and sigma = 20
kern <- se_kernel(l = 100, sigma = 20)
y <- shorter_data$temp
x <- shorter_data$time
# GP with variance sigma_f^2
#compute the variance from the residuals
quad_fit <- lm(temp ~ time + I(time^2), data = shorter_data)
sigma_n2 <- summary(quad_fit)$sigma^2
#get the gp_model
gp_model <- gausspr(x =x, y =y, kernel = kern,
scaled = FALSE)
#predict the posteriors
library("kernlab")
#import the data set
data <- read.csv("https://github.com/STIMALiU/AdvMLCourse/raw/master/GaussianProcess/Code/TempTullinge.csv", header=TRUE, sep=";")
#extend the data with variable time, which just tracks days since start of the data set
data$time <- 1:nrow(data)
#day, which tracks which day or the year
data$day <- (data$time %% 365)
#important to replace each 0 with 365
data$day[which(data$day == 0)] <- 365
#use only every 6th element to speed up computations of the gp
shorter_data <- data[seq(1,nrow(data), 5), ]
#print the "true function" for
plot(shorter_data$temp, type = "l")
#calculate distribution of estimated function from a gaussian process u
model <- gausspr(temp ~ time + day, data = shorter_data)
#use the predict function to get the posterior means for each data point
posterior_means <- predict(model, shorter_data)
plot(posterior_means, type = "l")
#define our own square exponential kernel function
se_kernel <- function(l, sigma, x, y){
k <- function(x, y) {
sigma^2 * exp(-sum((x - y)^2) / (2 * l^2))
}
class(k) <- "kernel"
return(k)
}
# se_kernel <- function(l, sigma, x, y){
#   x <- as.matrix(x)
#   y <- as.matrix(y)
#   x_len = nrow(x)
#   y_len = nrow(y)
#   kernel_matrix <- matrix(nrow = x_len, ncol = y_len)
#   for(i in 1:x_len){
#     for(j in 1:y_len){
#       kernel_matrix[i,j] <- sum((x[i,] - y[j,])^2)
#     }
#   }
#   kernel_matrix <- sigma^2*exp(-kernel_matrix/(2*l^2))
#   return(kernel_matrix)
# }
#evaluate covariance of x=1 and x' = 2 with our function
cov_1 <- se_kernel(l = 1, sigma = 1, x = 1, y = 2)
print(cov_1)
#use the kernelMatrix function
#to compute the covariance matrix K(X, X∗) for the input vectors X = (1, 3, 4)T and
# X∗ = (2, 3, 4)T
x <- c(1, 3, 4)
y <- c(2, 3, 4)
#we set l = 1
l <- 1
k <- se_kernel(l = 1, sigma = 1)
cov_2 <- kernelMatrix(k, x, y)
print(cov_2)
#set the kernel with l = 100 and sigma = 20
kern <- se_kernel(l = 100, sigma = 20)
y <- shorter_data$temp
x <- shorter_data$time
# GP with variance sigma_f^2
#compute the variance from the residuals
quad_fit <- lm(temp ~ time + I(time^2), data = shorter_data)
sigma_n2 <- summary(quad_fit)$sigma^2
#get the gp_model
gp_model <- gausspr(x =x, y =y, kernel = kern,
scaled = FALSE)
#predict the posteriors
posterior_mean <- predict(gp_model, x)
#compute posterior variance manually for 95% bands
K <- as.matrix(kernelMatrix(kern, x))
Ky <- K+diag(sigma_n2, nrow(K))
alpha <- solve(Ky, y)
m_post <- K %*% alpha
C_post <- K - K %*% solve(Ky, K)
var_post <- pmax(0, diag(C_post))
sd_post <- sqrt(var_post)
upper <- m_post + 1.96 * sd_post
lower <- m_post - 1.96 * sd_post
# --- Plot results ---
plot(shorter_data$time, shorter_data$temp, pch = 16, cex = 0.6,
xlab = "Time", ylab = "Temperature", main = "GP posterior mean and 95% bands")
ord <- order(shorter_data$time)
lines(shorter_data$time[ord], m_post[ord], col = "blue", lwd = 2)
lines(shorter_data$time[ord], upper[ord], col = "red", lty = 2)
lines(shorter_data$time[ord], lower[ord], col = "red", lty = 2)
legend("topright", legend = c("data", "posterior mean", "95% bands"),
pch = c(16, NA, NA), lty = c(NA, 1, 2), col = c("black", "blue", "red"))
